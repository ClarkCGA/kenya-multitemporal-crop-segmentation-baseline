# Custom dataset params
src_dir: "/home/data"
train_dataset_name: "test"
split_ratio: 0.8
apply_normalization: true
transformations:
  - "v_flip"
  - "h_flip"
  - "d_flip"
  - "rotate"
  - "resize"
aug_params:
  scale_factor:
    - 0.75
    - 1.3
  rotation_degree:
    - -180
    - -90
    - 90
    - 180
  bshift_gamma_range:
    - 0.2
    - 2
  bshift_subs:
    - 4
    - 4
    - 4
  patch_shift: true

# DataLoader
train_BatchSize: 8
val_test_BatchSize: 1

# model initialization params
n_classes: 14
input_channels: 12

# Model compiler params
working_dir: "/home/workdir"
out_dir: "output"
gpuDevices:
  - 0
init_type: "kaiming"
params_init: null
freeze_params: null

# Model fitting
epochs: 100
optimizer: "SGD"
LR: 0.003
LR_policy: "PolynomialLR"
criterion: "BalancedTverskyFocalCELoss(ignore_index=0)"
momentum: 0.95
resume: false
resume_epoch: null

lr_prams:
  step_size: 3
  milestones:
    - 5
    - 10
    - 20
    - 35
    - 50
    - 70
    - 90
  gamma: 0.98
  mode: "min"
  factor: 0.8
  patience: 3
  threshold: 0.0001
  threshold_mode: "rel"
  min_lr: 3e-6
  max_decay_steps: 75
  min_learning_rate: 1e-5
  power: 0.8
  base_lr: 3e-5
  max_lr: 0.01
  step_size_up: 1100

# Model accuracy evaluation
val_metric_fname: "validate_metrics.csv"
