import yaml
import numpy as np

config = {
    # Custom dataset params
    "src_dir": "/home/data",
    "train_dataset_name": "chips_filtered",
    "train_csv_path": "/home/workdir/train_ids.csv",
    "val_csv_path": "/home/workdir/val_ids.csv",
    "split_ratio": 0.8,
    "apply_normalization": True,
    "normal_strategy": "min_max",
    "stat_procedure": "lpb",
    "global_stats": {
        "min": np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0] * 3).tolist(),
        "max": np.array([300.0, 350.0, 500.0, 800.0, 900.0, 850.0] * 3).tolist(),
        "mean": np.array([524.299965, 852.201097, 987.414649,
                          2948.727491, 2712.733024, 1827.229407] * 3).tolist(),
        "std": np.array([294.751052, 370.654275, 596.312886,
                         858.965608, 955.384411, 938.537931] * 3).tolist()
    },
    "transformations": [
        "v_flip", "h_flip", "d_flip",
        "rotate", "resize", "shift_brightness"
    ],
    "aug_params": {
        "scale_factor": (0.75, 1.3),
        "rotation_degree": (-180, -90, 90, 180),
        "bshift_gamma_range": (0.2, 2),
        "bshift_subs": (6, 6, 6),
        "patch_shift": True
    },
    # DataLoader
    "train_BatchSize": 10,
    "val_test_BatchSize": 1,
    # Model initialization params
    "n_classes": 17,
    "input_channels": 18,
    "filter_config": (64, 128, 256, 512, 1024, 1024),
    "use_skipAtt": False,
    "train_dropout_rate": 0.15,
    # Model compiler params
    "working_dir": "/home/workdir",
    "out_dir": "output1",
    "class_mapping": {
        0: "Unknown", 1: "Shrubland", 2: "Grassland/Pasture",
        3: "Forest", 4: "Corn", 5: "Soybeans", 6: "Wetlands",
        7: "Developed", 8: "Open Water", 9: "Winter Wheat",
        10: "Other Hay/Non Alfalfa", 11: "Alfalfa",
        12: "Fallow/Idle Cropland", 13: "Barren",
        14: "Cotton", 15: "Sorghum", 16: "Other"
    },
    "gpuDevices": [0],
    "init_type": "kaiming",
    "params_init": "/home/data/chkpt/Unet_final_state.pth",
    "freeze_params": None,
    # Model fitting
    "epochs": 75,
    "optimizer": "sam",
    "LR": 0.01,
    "LR_policy": "PolynomialLR",
    "criterion": ("TverskyFocalLoss(weight=[0.023839441, 0.141533235, 0.115825893,"
                  "0.14021708, 0.124164449, 0.095742291, 0.080351933, 0.029785156,"
                  "0.042391139, 0.029357087, 0.03725627, 0.033638325, 0.001587225,"
                  "0.020611555, 0.017460882, 0.066238038], ignore_index=0, gamma=0.9)"),
    "momentum": 0.95,
    "resume": False,
    "resume_epoch": None,
    "lr_prams": {
        # StepLR & MultiStepLR
        "step_size": 3,
        "milestones": [5, 10, 20, 35, 50, 70, 90],
        "gamma": 0.98,
        # ReduceLROnPlateau
        "mode": "min",
        "factor": 0.8,
        "patience": 3,
        "threshold": 0.0001,
        "threshold_mode": "rel",
        "min_lr": 3e-6,
        # PolynomialLR
        "max_decay_steps": 50,
        "min_learning_rate": 1e-5,
        "power": 0.85,
        # CyclicLR
        "base_lr": 3e-5,
        "max_lr": 0.01,
        "step_size_up": 1100,
        "mode": "triangular"
    },
    # Model accuracy evaluation
    "val_metric_fname": "validate_metrics_global_V4.csv"
}

# Writing the config dictionary to a YAML file
with open('config.yaml', 'w') as file:
    yaml.dump(config, file)

