{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "74f68633-9cca-45d7-890d-fc5ae4d28247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import rioxarray\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from PIL import Image\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2754de-de8c-4c4b-be97-da1cce9b10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = \"SCPFF8IH374PYXFUN6SBBNT2\"\n",
    "AWS_SECRET_ACCESS_KEY = \"d6g1PEP4DRVTcsLipCqT1wPRVcbjAnwg1MAAzRi7UBb7SRNF0LoLQCV6Xd7a0beK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a18ba461-b665-49dc-8213-18ed5e44d75d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = Path('/app/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b43d4d3c-e477-440a-966f-ff6e92c20b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_keys(bucket_name, prefix):\n",
    "    keys = []\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "        for obj in page.get('Contents', []):\n",
    "            keys.append(obj['Key'])\n",
    "            \n",
    "    return keys\n",
    "\n",
    "def check_tif_values(label_path):\n",
    "    with rasterio.open(label_path) as src:\n",
    "        data = src.read(1)  # Reading the first band\n",
    "\n",
    "        # Check if the values are outside the range 0, 1, 2, 3\n",
    "        if ((data == 0) | (data == 1) | (data == 2) | (data == 3)).all():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "class KenyaData(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 paths):\n",
    "        self.tif_paths = paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tif_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with rasterio.open(self.tif_paths[index]) as src:\n",
    "            image = src.read()\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9cc54a7c-59d0-4545-a45a-21117fec7cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2074 images detected\n",
      "2074 labels detected\n",
      "0 images missing from local data will be downloaded\n",
      "0 labels missing from local data will be downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading images...: 0it [00:00, ?it/s]\n",
      "downloading labels...: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2074 images after download operation\n",
      "2074 labels after download operation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "session = boto3.session.Session(aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "s3 = session.client('s3', endpoint_url=endpoint_url)\n",
    "\n",
    "endpoint_url = 'https://data.source.coop'\n",
    "bucket_name = \"ksa\"\n",
    "prefix = \"kenol-section\"\n",
    "\n",
    "image_dir = data_dir / 'images'\n",
    "label_dir = data_dir / 'labels'\n",
    "\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "image_dir.mkdir(exist_ok=True)\n",
    "label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "images = [chip.name for chip in list(image_dir.glob('*.tif'))]\n",
    "labels = [chip.name for chip in list(label_dir.glob('*.tif'))]\n",
    "\n",
    "print(f'{len(images)} images detected')\n",
    "print(f'{len(labels)} labels detected')\n",
    "\n",
    "keys = get_keys(bucket_name, prefix)\n",
    "\n",
    "labelkeys = [key.split(\"/\")[-1] for key in keys if key.startswith(\"kenol-section/Labels\")]\n",
    "imagekeys = [key.split(\"/\")[-1] for key in keys if key.startswith(\"kenol-section/Images\")]\n",
    "\n",
    "missing_images = list(set(imagekeys) - set(images))\n",
    "missing_labels = list(set(labelkeys) - set(labels))\n",
    "\n",
    "print(f'{len(missing_images)} images missing from local data will be downloaded')\n",
    "print(f'{len(missing_labels)} labels missing from local data will be downloaded')\n",
    "\n",
    "for chip_id in tqdm(missing_images, desc='downloading images...'):\n",
    "    s3.download_file(bucket_name, \"kenol-section/Images/\"+chip_id, image_dir / chip_id)\n",
    "    \n",
    "for chip_id in tqdm(missing_labels, desc='downloading labels...'):\n",
    "    s3.download_file(bucket_name, \"kenol-section/Labels/\"+chip_id, label_dir / chip_id)\n",
    "    \n",
    "images = list(image_dir.glob('*.tif'))\n",
    "labels = list(label_dir.glob('*.tif'))\n",
    "\n",
    "print(f'{len(images)} images after download operation')\n",
    "print(f'{len(labels)} labels after download operation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2c91f338-5a2c-4269-bf56-3bf92f77d04c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combining building classes into harmonized labels...: 100%|██████████| 2074/2074 [00:09<00:00, 212.28it/s]\n"
     ]
    }
   ],
   "source": [
    "harmonized_label_dir = data_dir / 'harmonized_labels'\n",
    "harmonized_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for label_path in tqdm(labels, desc=\"combining building classes into harmonized labels...\"):\n",
    "\n",
    "    with rasterio.open(label) as src:\n",
    "        data = src.read(1)  # Read the first band\n",
    "\n",
    "        data[data == 3] = 1\n",
    "\n",
    "        output_filepath = harmonized_label_dir / label_path.name\n",
    "\n",
    "        with rasterio.open(\n",
    "            output_filepath,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=data.shape[0],\n",
    "            width=data.shape[1],\n",
    "            count=1,\n",
    "            dtype=data.dtype,\n",
    "            crs=src.crs,\n",
    "            transform=src.transform\n",
    "            ) as dst:\n",
    "            dst.write(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ef55356e-31de-470d-8a56-c16924299d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_label_dir = data_dir / 'object_labels'\n",
    "buildingdir = object_label_dir / 'buildings'\n",
    "cropsdir = object_label_dir / 'crop_fields'\n",
    "\n",
    "object_label_dir.mkdir(exist_ok=True)\n",
    "buildingdir.mkdir(exist_ok=True)\n",
    "cropsdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e87ed0fd-2255-4bf3-a4d5-f52fe4fb26d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting individual object masks from labels...: 100%|██████████| 2074/2074 [01:15<00:00, 27.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for mask_file in tqdm(labels, desc='extracting individual object masks from labels...'):\n",
    "    example_groundtruth = rioxarray.open_rasterio(mask_file)\n",
    "    building_groundtruth = xr.where(example_groundtruth % 2 == 1, 1, 0)\n",
    "    field_groundtruth = xr.where(example_groundtruth==2, 1, 0)\n",
    "    \n",
    "    building_masks, building_num_labels = label(building_groundtruth)\n",
    "    building_object_masks = []\n",
    "    for i in range(1, building_num_labels + 1):\n",
    "        building_object_mask = xr.where(building_masks == i, 1, 0)\n",
    "        building_object_mask_xr = xr.DataArray(\n",
    "            building_object_mask, \n",
    "            coords=building_groundtruth.coords,\n",
    "            dims=building_groundtruth.dims,\n",
    "            attrs=building_groundtruth.attrs)\n",
    "        building_object_masks.append(building_object_mask_xr)\n",
    "        \n",
    "    field_masks, field_num_labels = label(field_groundtruth)\n",
    "    field_object_masks = []\n",
    "    for i in range(1, field_num_labels + 1):\n",
    "        field_object_mask = xr.where(field_masks == i, 1, 0)\n",
    "        field_object_mask_xr = xr.DataArray(\n",
    "            field_object_mask, \n",
    "            coords=field_groundtruth.coords,\n",
    "            dims=field_groundtruth.dims,\n",
    "            attrs=field_groundtruth.attrs)\n",
    "        field_object_masks.append(field_object_mask_xr)\n",
    "\n",
    "    for i, building_object_mask in enumerate(building_object_masks):\n",
    "        building_object_mask.rio.to_raster(buildingdir / (mask_file.name[:-4]+'_b'+str(i)+'.tif'))\n",
    "\n",
    "    for i, field_object_mask in enumerate(field_object_masks):\n",
    "        field_object_mask.rio.to_raster(cropsdir / (mask_file.name[:-4]+'_f'+str(i)+'.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "639f25ad-e07d-4b6a-8755-f5dac59da5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 chips will be filtered from the chip tracker due to containing invalid label integers\n",
      "chip tracker with training, validation, and test split saved to /app/dataset/chip_tracker.csv\n"
     ]
    }
   ],
   "source": [
    "valid = [label_path for label_path in labels if check_tif_values(label_path)]\n",
    "print(f'{len(labels) - len(valid)} chips will be filtered from the chip tracker due to containing invalid label integers')\n",
    "\n",
    "df = pd.DataFrame([label_path.name for label_path in valid], columns=['chip_id'])\n",
    "\n",
    "random.seed(42)\n",
    "p = [random.random() for n in range(len(valid))]\n",
    "df['p'] = p\n",
    "df.loc[df['p'] < 0.7, 'usage'] = 'train'\n",
    "df.loc[(df['p'] >= 0.7) & (df['p'] < 0.9), 'usage'] = 'validate'\n",
    "df.loc[df['p'] >= 0.9, 'usage'] = 'test'\n",
    "\n",
    "df = df.drop(columns=['p'])\n",
    "\n",
    "chip_tracker_path = data_dir / 'chip_tracker.csv'\n",
    "\n",
    "df.to_csv(chip_tracker_path, index=False)\n",
    "print(f'chip tracker with training, validation, and test split saved to {chip_tracker_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "27cef249-6d4d-4357-8af4-43983c85cf18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating dataset statistics...: 100%|██████████| 256/256 [00:09<00:00, 27.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset statistics saved to /app/dataset/dataset_stats.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_images = [image_dir / label_path.name for label_path in valid]\n",
    "\n",
    "kenya_data = KenyaData(valid_images)\n",
    "\n",
    "# data loader\n",
    "kenya_dataloader = DataLoader(kenya_data, \n",
    "                          batch_size  = 8, \n",
    "                          shuffle     = False)\n",
    "\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "pmin    = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "pmax    = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for tensor in tqdm(kenya_dataloader, desc='calculating dataset statistics...'):\n",
    "    \n",
    "    psum    += tensor.sum(axis = [0, 2, 3])\n",
    "    psum_sq += (tensor ** 2).sum(axis = [0, 2, 3])\n",
    "    tensor_min = torch.amin(tensor, (0, 2, 3))\n",
    "    tensor_max = torch.amax(tensor, (0, 2, 3))\n",
    "    pmin = torch.min(tensor_min, pmin)\n",
    "    pmax = torch.max(tensor_max, pmax)\n",
    "    \n",
    "count = len(kenya_data) * 512 * 512\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "bands = ['red', 'green', 'blue', 'alpha']\n",
    "\n",
    "stats_dict = {'bands' : bands,\n",
    "              'mean': total_mean.numpy(),\n",
    "              'std': total_std.numpy(),\n",
    "              'min': pmin.numpy(),\n",
    "              'max': pmax.numpy()\n",
    "             }\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "\n",
    "stats_path = data_dir / 'dataset_stats.csv'\n",
    "\n",
    "stats_df.to_csv(stats_path, index=False)\n",
    "print(f'dataset statistics saved to {stats_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e153c7-e3fd-41ea-851a-3eece185d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo 12/28: Use samgeo to get process all the chips in the ways that we need to\n",
    "# this will conclude the data processing pipeline\n",
    "# and we can create a python script and test it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
