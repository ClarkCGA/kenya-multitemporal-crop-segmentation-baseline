{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e206e0-bf7e-4957-b43e-e657f00a2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import rasterio\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7aae044-b585-4a42-bb3e-d08839c157ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteData(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 root):\n",
    "        self.root_dir = pathlib.Path(root)\n",
    "        self.image_dir = self.root_dir.joinpath(\"images\")\n",
    "        self.tif_paths = self._get_tif_paths()\n",
    "\n",
    "\n",
    "    def _get_tif_paths(self):\n",
    "        tif_paths = [self.image_dir.joinpath(i) for i in os.listdir(self.image_dir)]\n",
    "        return tif_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tif_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        def read_tif_as_np_array(path):\n",
    "            with rasterio.open(path) as src:\n",
    "                    return src.read()\n",
    "\n",
    "        # Read in merged tif as ground truth\n",
    "        groundtruth = read_tif_as_np_array(self.tif_paths[index])\n",
    "        groundtruth = torch.tensor(groundtruth, dtype=torch.float32)\n",
    "        return groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734f76ad-19cf-4c62-8062-8309a775fa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 4, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "image_dataset = SatelliteData(root = \"/home/data\")\n",
    "\n",
    "# data loader\n",
    "image_loader = DataLoader(image_dataset, \n",
    "                          batch_size  = 320, \n",
    "                          shuffle     = False)\n",
    "\n",
    "# display images\n",
    "for batch_idx, inputs in enumerate(image_loader):\n",
    "    print(inputs.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f849900-4795-454a-b143-84fb7bf441c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "psum    = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "\n",
    "# loop through images\n",
    "for tensor in tqdm(image_loader):\n",
    "    \n",
    "    psum    += tensor.sum(axis = [0, 2, 3])\n",
    "    psum_sq += (tensor ** 2).sum(axis = [0, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "531bee87-4df0-456a-a3c3-dbf2b28af8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:09<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.])\n",
      "tensor([255., 255., 255., 255.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pmin    = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "pmax    = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "for tensor in tqdm(image_loader):\n",
    "    tensor_min = torch.amin(tensor, (0, 2, 3))\n",
    "    tensor_max = torch.amax(tensor, (0, 2, 3))\n",
    "    pmin = torch.min(tensor_min, pmin)\n",
    "    pmax = torch.max(tensor_max, pmax)\n",
    "\n",
    "print(pmin)\n",
    "print(pmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10db185e-6d89-4d92-b61f-fa828d51eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([112.1533, 114.1895,  92.9912, 254.9901])\n",
      "std:  tensor([39.2668, 34.4827, 34.6238,  1.5245])\n"
     ]
    }
   ],
   "source": [
    "count = len(image_dataset) * 512 * 512\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b01b84-6223-4071-9751-233e7bdb210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2074\n"
     ]
    }
   ],
   "source": [
    "print(len(image_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
