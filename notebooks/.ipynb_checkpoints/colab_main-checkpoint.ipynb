{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "zJsyIGqB_9Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "hCPUsc1FACPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, copy, time, math, random, numbers, itertools, tqdm, importlib, re\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import cv2\n",
        "import rasterio\n",
        "import torch\n",
        "\n",
        "from sklearn import metrics\n",
        "from skimage import transform as trans\n",
        "from pathlib import Path\n",
        "from collections.abc import Sequence\n",
        "from datetime import datetime, timedelta\n",
        "from scipy.ndimage import rotate\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "wxwiBLm8xua3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utilities\n",
        "\n",
        "def load_data(data_path, is_label=False, apply_normalization=False, dtype=np.float32, verbose=False):\n",
        "    r\"\"\"\n",
        "    Open data using gdal, read it as an array and normalize it.\n",
        "\n",
        "    Arguments:\n",
        "            data_path (string) -- Full path including filename of the data source we wish to load.\n",
        "            is_label (binary) -- If True then the layer is a ground truth (category index) and if\n",
        "                                set to False the layer is a reflectance band.\n",
        "            apply_normalization (binary) -- If true min/max normalization will be applied on each band.\n",
        "            dtype (np.dtype) -- Data type of the output image chips.\n",
        "            verbose (binary) -- if set to true, print a screen statement on the loaded band.\n",
        "\n",
        "    Returns:\n",
        "            image -- Returns the loaded image as a 32-bit float numpy ndarray.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inform user of the file names being loaded from the Dataset.\n",
        "    if verbose:\n",
        "        print('loading file:{}'.format(data_path))\n",
        "\n",
        "    # open dataset using rasterio library.\n",
        "    with rasterio.open(data_path, \"r\") as src:\n",
        "\n",
        "        if is_label:\n",
        "            if src.count != 1:\n",
        "                raise ValueError(\"Expected Label to have exactly one channel.\")\n",
        "            img = src.read(1)\n",
        "\n",
        "        else:\n",
        "            if apply_normalization:\n",
        "                img = do_normalization(src.read(), bounds=(0, 1), clip_val=1)\n",
        "                img = img.astype(dtype)\n",
        "            else:\n",
        "                img = src.read()\n",
        "                img = img.astype(dtype)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_deterministic(seed=None, cudnn=True):\n",
        "    \"\"\"\n",
        "    Sets the random seed for Python, NumPy, and PyTorch to a fixed value to ensure \n",
        "    reproducibility of results. Optionally, sets the seed for the CuDNN backend to \n",
        "    ensure reproducibility when training on a GPU.\n",
        "\n",
        "    Args:\n",
        "        seed (int): The seed value to use for setting the random seed (default: 1960).\n",
        "        cudnn (bool): If True, sets the seed for the CuDNN backend to ensure \n",
        "            reproducibility when training on a GPU (default: True).\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = int(time.time()) + int(os.getpid())\n",
        "    \n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    if cudnn:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "cellView": "form",
        "id": "arwej78iy-Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y_lSJVekxDjg"
      },
      "outputs": [],
      "source": [
        "#@title Input Normalization\n",
        "\n",
        "def do_normalization(img, normal_strategy=\"min_max\", bounds=(0, 1), clip_val=None):\n",
        "    \"\"\"\n",
        "    Normalize the input image pixels to a user-defined range based on the\n",
        "    minimum and maximum statistics of each band and optional clip value.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Stacked image bands with a dimension of (C, H, W).\n",
        "        normal_strategy (str): Strategy for normalization. Either 'min_max'\n",
        "                               or 'z_value'.\n",
        "        bounds (tuple): Lower and upper bound of rescaled values applied to all\n",
        "                        the bands in the image. Default is (0, 1).\n",
        "        clip_val (float): Defines how much of the distribution tails to be cut off.\n",
        "                          Default is None.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalized image stack of size (C, H, W).\n",
        "\n",
        "    Notes:\n",
        "        - Most common bounds for satellite image processing would be (0, 1)\n",
        "          or (0, 256).\n",
        "        - Normalization statistics are calculated per band and for each image\n",
        "          tile separately.\n",
        "    \"\"\"\n",
        "\n",
        "    if normal_strategy not in [\"min_max\", \"z_value\"]:\n",
        "        raise ValueError(\"Normalization strategy is not recognized.\")\n",
        "\n",
        "    if not isinstance(bounds, (tuple, list)) or len(bounds) != 2:\n",
        "        raise ValueError(\"Normalization bounds should be a tuple or list of length 2.\")\n",
        "\n",
        "    lower_bound, upper_bound = map(float, bounds)\n",
        "\n",
        "    img_mins = np.nanmin(img, axis=(1, 2))\n",
        "    img_maxs = np.nanmax(img, axis=(1, 2))\n",
        "\n",
        "    if normal_strategy == \"min_max\":\n",
        "        if clip_val is not None:\n",
        "            img = np.clip(img, np.nanpercentile(img, clip_val),\n",
        "                          np.nanpercentile(img, 100 - clip_val))\n",
        "\n",
        "        normal_img = (upper_bound - lower_bound) * (img - img_mins[:, None, None]) / (\n",
        "                img_maxs[:, None, None] - img_mins[:, None, None])\n",
        "\n",
        "    elif normal_strategy == \"z_value\":\n",
        "        img_means = np.nanmean(img, axis=(1, 2))\n",
        "        img_stds = np.nanstd(img, axis=(1, 2))\n",
        "        normal_img = (img - img_means[:, None, None]) / img_stds[:, None, None]\n",
        "\n",
        "    return normal_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Augmentation\n",
        "\n",
        "def center_rotate(img, label, degree):\n",
        "    r\"\"\"\n",
        "    Synthesize a new pair of image, label chips by rotating the input chip around its center.\n",
        "    Arguments:\n",
        "            img (ndarray) -- Stacked image bands with a dimension of (H,W,C).\n",
        "            label (ndarray) -- Ground truth layer with a dimension of (H,W).\n",
        "            degree (tuple or list) -- If the  passed argument has exactly two elements then they\n",
        "                                      act as a bound on the possible range of values to be used for rotation.\n",
        "                                      If number of elements is more than two then one element is chosen\n",
        "                                      randomly as the rotation degree.\n",
        "    Returns:\n",
        "        img -- A numpy array of rotated variables or brightness value.\n",
        "        label -- A numpy array of rotated ground truth.\n",
        "    \"\"\"\n",
        "\n",
        "    # Validate input parameters\n",
        "    if not isinstance(img, np.ndarray) or not isinstance(label, np.ndarray):\n",
        "        raise ValueError(\"img and label must be numpy arrays.\")\n",
        "    if img.ndim != 3:\n",
        "        raise ValueError(\"img must have dimensions (H, W, C).\")\n",
        "    if label.ndim != 2:\n",
        "        raise ValueError(\"label must have dimensions (H, W).\")\n",
        "    if not any(isinstance(degree, t) for t in (tuple, list)):\n",
        "        raise ValueError(\"Degree must be a tuple or a list.\")\n",
        "\n",
        "    # And draw a random degree between the bounds from a uniform distribution.\n",
        "    if len(degree) == 2:\n",
        "        rotation_degree = random.uniform(degree[0], degree[1])\n",
        "    elif len(degree) > 2:\n",
        "        rotation_degree = random.choice(degree)\n",
        "    else:\n",
        "        raise ValueError(\"Parameter degree needs at least two elements.\")\n",
        "\n",
        "    # Get the spatial dimensions of the image.\n",
        "    h, w = label.shape\n",
        "\n",
        "    # Determine the image center.\n",
        "    center = (w // 2, h // 2)\n",
        "\n",
        "    # Grab the rotation matrix.\n",
        "    # Third arg --> scale: Isotropic scale factor.\n",
        "    rot_matrix = cv2.getRotationMatrix2D(center, rotation_degree, 1.0)\n",
        "\n",
        "    # perform the actual rotation on image and label.\n",
        "    img = cv2.warpAffine(img, rot_matrix, (w, h))\n",
        "    label = cv2.warpAffine(label, rot_matrix, (w, h))\n",
        "\n",
        "    # Round all pixel values greater than 0.5 to 1 and assign zero to the rest.\n",
        "    label = np.rint(label)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "\n",
        "# use scipy package if there is issue installing opencv\n",
        "def rotate_image_and_label(image, label, angle):\n",
        "    \"\"\"\n",
        "    Applies rotation augmentation to an image patch and label.\n",
        "\n",
        "    Args:\n",
        "        image (numpy array) : The input image patch as a numpy array.\n",
        "        label (numpy array) : The corresponding label as a numpy array.\n",
        "        angle (list of floats) : If the list has exactly two elements they will\n",
        "            be considered the lower and upper bounds for the rotation angle\n",
        "            (in degrees) respectively. If number of elements are bigger than 2,\n",
        "            then one value is chosen randomly as the rotation angle.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the rotated image patch and label as numpy arrays.\n",
        "    \"\"\"\n",
        "    if isinstance(angle, tuple) or isinstance(angle, list):\n",
        "        if len(angle) == 2:\n",
        "            rotation_degree = random.uniform(angle[0], angle[1])\n",
        "        elif len(angle) > 2:\n",
        "            rotation_degree = random.choice(angle)\n",
        "        else:\n",
        "            raise ValueError(\"Parameter angle needs at least two elements.\")\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Rotation bound param for augmentation must be a tuple or list.\"\n",
        "        )\n",
        "\n",
        "    # Apply rotation augmentation to the image patch\n",
        "    rotated_image = rotate(input=image, angle=rotation_degree, axes=(1,0),\n",
        "                           reshape=False, mode='reflect')\n",
        "\n",
        "    # Apply rotation augmentation to the label\n",
        "    rotated_label = rotate(input=label, angle=rotation_degree, axes=(1,0),\n",
        "                           reshape=False, mode='nearest')\n",
        "\n",
        "    # Return the rotated image patch and label as a tuple\n",
        "    return rotated_image.copy(), rotated_label.copy()\n",
        "\n",
        "\n",
        "def flip(img, label, flip_type):\n",
        "    r\"\"\"\n",
        "    Synthesize a new pair of image, label chips by flipping the input chips around a user defined axis.\n",
        "\n",
        "    Arguments:\n",
        "            img (ndarray) -- Concatenated variables or brightness value with a dimension of (H,W,C)\n",
        "            label (ndarray) -- Ground truth with a dimension of (H,W)\n",
        "            flip_type (list) -- A flip type based on the choice of axis.\n",
        "                                Provided transformation are:\n",
        "                                    1) 'v_flip', vertical flip\n",
        "                                    2) 'h_flip', horizontal flip\n",
        "                                    3) 'd_flip', diagonal flip\n",
        "    Returns:\n",
        "            img -- A numpy array of flipped variables or brightness value.\n",
        "            label --A numpy array of flipped labeled reference (ground truth).\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(img, np.ndarray) or not isinstance(label, np.ndarray):\n",
        "        raise ValueError(\"img and label must be numpy arrays.\")\n",
        "    if img.ndim != 3:\n",
        "        raise ValueError(\"img must have dimensions (H, W, C).\")\n",
        "    if label.ndim != 2:\n",
        "        raise ValueError(\"label must have dimensions (H, W).\")\n",
        "    if not isinstance(flip_type, str):\n",
        "        raise ValueError(\"Flip type must be a string.\")\n",
        "\n",
        "    # Horizontal flip\n",
        "    if flip_type == \"h_flip\":\n",
        "        img = np.flip(img, 0)\n",
        "        label = np.flip(label, 0)\n",
        "\n",
        "    # Vertical flip\n",
        "    elif flip_type == \"v_flip\":\n",
        "        img = np.flip(img, 1)\n",
        "        label = np.flip(label, 1)\n",
        "\n",
        "    # Diagonal flip\n",
        "    elif flip_type == \"d_flip\":\n",
        "        img = np.transpose(img, axes=(1, 0))\n",
        "        label = np.transpose(label, axes=(1, 0))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported flip type. Valid options are: 'h_flip', 'v_flip', 'd_flip'.\")\n",
        "\n",
        "    return img.copy(), label.copy()\n",
        "\n",
        "\n",
        "def re_scale(img, label, scale=(0.75, 1.5), crop_strategy=\"center\"):\n",
        "    r\"\"\"\n",
        "    Synthesize a new pair of image, label chips by rescaling the input chips.\n",
        "\n",
        "    Arguments:\n",
        "            img (ndarray) -- Image chip with a dimension of (H,W,C).\n",
        "            label (ndarray) -- Reference annotation layer with a dimension of (H,W).\n",
        "            scale (tuple or list) -- A range of scale ratio.\n",
        "            crop_strategy (str) -- decides whether to crop the rescaled image chip randomly\n",
        "                                   or at the center.\n",
        "    Returns:\n",
        "           Tuple[np.ndarray, np.ndarray] including:\n",
        "            resampled_img -- A numpy array of rescaled variables or brightness values in the\n",
        "                             same size as the input chip.\n",
        "            resampled_label --A numpy array of flipped ground truth in the same size as input.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(img, np.ndarray) or not isinstance(label, np.ndarray):\n",
        "        raise ValueError(\"img and label must be numpy arrays.\")\n",
        "    if img.ndim != 3:\n",
        "        raise ValueError(\"img must have dimensions (H, W, C).\")\n",
        "    if label.ndim != 2:\n",
        "        raise ValueError(\"label must have dimensions (H, W).\")\n",
        "\n",
        "    h, w, c = img.shape\n",
        "\n",
        "    if isinstance(scale, Sequence):\n",
        "        resize_h = round(random.uniform(scale[0], scale[1]) * h)\n",
        "        resize_w = resize_h\n",
        "    else:\n",
        "        raise Exception('Wrong scale type!')\n",
        "\n",
        "    assert crop_strategy in [\"center\", \"random\"], \"'crop_strategy' is not recognized.\"\n",
        "\n",
        "    # We are using a bi-linear interpolation by default for resampling.\n",
        "    # When output image size is zero then the output size is calculated based on fx and fy.\n",
        "    resampled_img = trans.resize(img, (resize_h, resize_w), preserve_range=True)\n",
        "    resampled_label = trans.resize(label, (resize_h, resize_w), preserve_range=True)\n",
        "\n",
        "    if crop_strategy == \"center\":\n",
        "        x_off = max(0, abs(resize_h - h) // 2)\n",
        "        y_off = max(0, abs(resize_w - w) // 2)\n",
        "    elif crop_strategy == \"random\":\n",
        "        x_off = random.randint(0, max(0, abs(resize_h - h)))\n",
        "        y_off = random.randint(0, max(0, abs(resize_w - w)))\n",
        "\n",
        "    canvas_img = np.zeros((h, w, c), dtype=img.dtype)\n",
        "    canvas_label = np.zeros((h, w), dtype=label.dtype)\n",
        "\n",
        "    if resize_h > h and resize_w > w:\n",
        "        canvas_img = resampled_img[x_off: x_off + min(h, resize_h), y_off: y_off + min(w, resize_w), :]\n",
        "        canvas_label = resampled_label[x_off: x_off + min(h, resize_h), y_off: y_off + min(w, resize_w)]\n",
        "        canvas_label = np.rint(canvas_label)\n",
        "\n",
        "    elif resize_h < h and resize_w < w:\n",
        "        canvas_img[x_off: x_off + resize_h, y_off: y_off + resize_w] = resampled_img\n",
        "        canvas_label[x_off: x_off + resize_h, y_off: y_off + resize_w] = resampled_label\n",
        "\n",
        "    return canvas_img, canvas_label\n",
        "\n",
        "\n",
        "def shift_brightness(img, gamma_range=(0.2, 2.0), shift_subset=(4, 4, 4), patch_shift=False):\n",
        "    \"\"\"\n",
        "    Shift image brightness through gamma correction\n",
        "\n",
        "    Params:\n",
        "\n",
        "        img (ndarray): Concatenated variables or brightness value with a dimension of (H, W, C)\n",
        "        gamma_range (tuple): Range of gamma values\n",
        "        shift_subset (tuple): Number of bands or channels for each shift\n",
        "        patch_shift (bool): Whether apply the shift on small patches\n",
        "\n",
        "     Returns:\n",
        "\n",
        "        ndarray, brightness shifted image\n",
        "\n",
        "    \"\"\"\n",
        "    c_start = 0\n",
        "    for i in shift_subset:\n",
        "        gamma = random.triangular(gamma_range[0], gamma_range[1], 1)\n",
        "        if patch_shift:\n",
        "            # shift on patch\n",
        "            # generate mask - random rotate or/and rescale\n",
        "\n",
        "            h, w, _ = img.shape\n",
        "            rotMtrx = cv2.getRotationMatrix2D(center=(random.randint(0, h), random.randint(0, w)),\n",
        "                                              angle=random.randint(0, 90),\n",
        "                                              scale=random.uniform(1, 2))\n",
        "            mask = cv2.warpAffine(img[:, :, c_start:c_start + i], rotMtrx, (w, h))\n",
        "            mask = np.where(mask, 0, 1)\n",
        "            # apply mask\n",
        "            img_ma = ma.masked_array(img[:, :, c_start:c_start + i], mask=mask)\n",
        "            img[:, :, c_start:c_start + i] = ma.power(img_ma, gamma)\n",
        "            # default extra step -- shift on image\n",
        "            gamma_full = random.triangular(0.5, 1.5, 1)\n",
        "            img[:, :, c_start:c_start + i] = np.power(img[:, :, c_start:c_start + i], gamma_full)\n",
        "\n",
        "        else:\n",
        "            img[:, :, c_start:c_start + i] = np.power(img[:, :, c_start:c_start + i], gamma)\n",
        "        c_start += i\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def gaussian_blur(img, kernel_size):\n",
        "    \"\"\"\n",
        "        Apply Gaussian blur to the input image.\n",
        "\n",
        "        Args:\n",
        "            img (np.ndarray): Input image as a NumPy array.\n",
        "            kernel_size (int): Size of the Gaussian kernel.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Blurred image as a NumPy array.\n",
        "\n",
        "        Note:\n",
        "            The sigmaX parameter specifies the standard deviation of the Gaussian\n",
        "            kernel along the x-axis, and if set to 0, OpenCV automatically computes\n",
        "            it based on the kernel size using the formula:\n",
        "            sigma = 0.3 * ((kernel_size - 1) * 0.5 - 1) + 0.8.\n",
        "        \"\"\"\n",
        "    # When sigma=0, it is computed as `sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8`\n",
        "    aug_img = cv2.GaussianBlur(img, (kernel_size, kernel_size), sigmaX=0)\n",
        "\n",
        "    return aug_img\n",
        "\n",
        "\n",
        "def adjust_brightness(img, value=-0.2):\n",
        "    \"\"\"\n",
        "    Adjust the brightness of the input image by adding a value to each pixel.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Input image as a NumPy array.\n",
        "        value (float): Value to be added to each pixel to adjust brightness. Default is -0.2.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image with adjusted brightness as a NumPy array.\n",
        "\n",
        "    Notes:\n",
        "        - If the input image has a floating-point \"dtype\" (np.float, np.float32, np.float64),\n",
        "            the pixel values are assumed to be in the range [0, 1].\n",
        "        - If the input image has an integer \"dtype\", the pixel values are assumed to be in the\n",
        "            range specified by the \"dtype\" (e.g., [0, 255] for np.uint8).\n",
        "        - The adjusted pixel values are clipped to the minimum and maximum values allowed\n",
        "            by the \"dtype\" of the input image.\n",
        "    \"\"\"\n",
        "    if img.dtype in [np.float, np.float32, np.float64]:\n",
        "        dtype_min, dtype_max = 0, 1\n",
        "        dtype = np.float32\n",
        "    else:\n",
        "        dtype_min = np.iinfo(img.dtype).min\n",
        "        dtype_max = np.iinfo(img.dtype).max\n",
        "        dtype = np.iinfo(img.dtype)\n",
        "\n",
        "    aug_img = np.clip(img.astype(np.float) + value, dtype_min, dtype_max).astype(dtype)\n",
        "\n",
        "    return aug_img\n",
        "\n",
        "\n",
        "def adjust_contrast(img, factor=1):\n",
        "    \"\"\"\n",
        "    Adjust the contrast of the input image by multiplying it with a contrast factor.\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Input image as a NumPy array.\n",
        "        factor (float): Contrast factor to adjust the contrast. Default is 1.0.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image with adjusted contrast as a NumPy array.\n",
        "    \"\"\"\n",
        "    if img.dtype in [np.float, np.float32, np.float64]:\n",
        "        dtype_min, dtype_max = 0, 1\n",
        "        dtype = np.float32\n",
        "    else:\n",
        "        dtype_min = np.iinfo(img.dtype).min\n",
        "        dtype_max = np.iinfo(img.dtype).max\n",
        "        dtype = np.iinfo(img.dtype)\n",
        "\n",
        "    aug_img = np.clip(img.astype(np.float) * factor, dtype_min, dtype_max).astype(dtype)\n",
        "\n",
        "    return aug_img"
      ],
      "metadata": {
        "cellView": "form",
        "id": "l6oYLVTcx4t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom loss functions\n",
        "\n",
        "class BalancedCrossEntropyLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Balanced cross entropy loss by weighting of inverse class ratio.\n",
        "\n",
        "    Args:\n",
        "        ignore_index (int): Class index to ignore.\n",
        "        reduction (str): Reduction method to apply to loss.\n",
        "                         Options: 'mean', 'sum', 'none'.\n",
        "        weight_scheme (str): Strategy to weight samples. Options:\n",
        "                      \"icr\" -- inverse class ratio\n",
        "                      \"mcf\" -- median class frequency\n",
        "\n",
        "    Returns:\n",
        "        Loss tensor according to the specified reduction.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ignore_index=-100, reduction=\"mean\", weight_scheme=\"icr\"):\n",
        "        super(BalancedCrossEntropyLoss, self).__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "        self.reduction = reduction\n",
        "\n",
        "        assert weight_scheme in [\"icr\", \"mcf\"], \"'weight_scheme' is not recognized.\"\n",
        "        self.weight_scheme = weight_scheme\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            predict (torch.Tensor): Predicted output tensor.\n",
        "            target (torch.Tensor): Target tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        class_counts = torch.bincount(target.view(-1), minlength=predict.shape[1])\n",
        "        # get class weights\n",
        "        if self.weight_scheme == \"icr\":\n",
        "            class_weights = 1.0 / torch.sqrt(class_counts.float())\n",
        "        else:\n",
        "            median_frequency = torch.median(class_counts.float())\n",
        "            class_weights = median_frequency / class_counts.float()\n",
        "\n",
        "        # set weight of ignore index to 0\n",
        "        if self.ignore_index >= 0 and self.ignore_index < len(class_weights):\n",
        "            class_weights[self.ignore_index] = 0\n",
        "\n",
        "        # normalize weights\n",
        "        class_weights /= torch.sum(class_weights)\n",
        "\n",
        "        # apply class weights to loss function\n",
        "        loss_fn = nn.CrossEntropyLoss(weight=class_weights, ignore_index=self.ignore_index,\n",
        "                                      reduction=self.reduction)\n",
        "\n",
        "        return loss_fn(predict, target)\n",
        "\n",
        "class OhemCrossEntropyLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Online Hard Example Mining (OHEM) Cross Entropy Loss for Semantic Segmentation\n",
        "    Params:\n",
        "        ignore_index (int): Class index to ignore\n",
        "        reduction (str): Reduction method to apply to loss, return mean over batch if 'mean',\n",
        "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
        "        ohem_ratio (float): Ratio of hard examples to use in the loss function\n",
        "\n",
        "    Returns:\n",
        "        Loss tensor according to arg reduction\n",
        "    \"\"\"\n",
        "    def __init__(self, ignore_index=-100, reduction='mean', ohem_ratio=0.25):\n",
        "        super(OhemCrossEntropyLoss, self).__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "        self.reduction = reduction\n",
        "        self.ohem_ratio = ohem_ratio\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        # calculate pixel-wise cross entropy loss\n",
        "        loss_fn = nn.CrossEntropyLoss(ignore_index=self.ignore_index, reduction='none')\n",
        "        pixel_losses = loss_fn(predict, target)\n",
        "\n",
        "        # apply online hard example mining\n",
        "        num_hard = int(self.ohem_ratio * pixel_losses.numel())\n",
        "        _, top_indices = pixel_losses.flatten().topk(num_hard)\n",
        "        ohem_losses = pixel_losses.flatten()[top_indices]\n",
        "\n",
        "        # apply reduction to ohem losses\n",
        "        if self.reduction == 'mean':\n",
        "            loss = ohem_losses.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = ohem_losses.sum()\n",
        "        else:\n",
        "            loss = ohem_losses\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    '''\n",
        "        Dice loss of binary class\n",
        "        Params:\n",
        "            smooth (float): A float number to smooth loss, and avoid NaN error, default: 1\n",
        "            p (int): Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2. Used\n",
        "                     to control the sensitivity of the loss.\n",
        "            predict (torch.tensor): Predicted tensor of shape [N, *]\n",
        "            target (torch.tensor): Target tensor of same shape with predict\n",
        "        Returns:\n",
        "            Loss tensor\n",
        "    '''\n",
        "    def __init__(self, smooth=1, p=1):\n",
        "        super(BinaryDiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "\n",
        "        assert predict.shape == target.shape, \"predict & target shape do not match\"\n",
        "        assert predict.shape == target.shape, \"predict & target shapes do not match\"\n",
        "        assert predict.dtype == target.dtype, \"predict & target data types do not match\"\n",
        "\n",
        "        predict = predict.contiguous().view(-1)\n",
        "        target = target.contiguous().view(-1)\n",
        "\n",
        "        num = 2 * (predict * target).sum() + self.smooth\n",
        "        den = (predict.pow(self.p) + target.pow(self.p)).sum() + self.smooth\n",
        "        loss = 1 - num / den\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    r\"\"\"\n",
        "    Dice loss\n",
        "\n",
        "    Arguments:\n",
        "        weight (torch.tensor): Weight array of shape [num_classes,]\n",
        "        ignore_index (int): Class index to ignore\n",
        "        predict (torch.tensor): Predicted tensor of shape [N, C, *]\n",
        "        target (torch.tensor): Target tensor either in shape [N,*] or of same shape with predict\n",
        "        other args pass to BinaryDiceLoss\n",
        "    Returns:\n",
        "        same as BinaryDiceLoss\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, ignore_index=-100, **kwargs):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.kwargs = kwargs\n",
        "        self.weight = weight\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        nclass = predict.shape[1]\n",
        "        if predict.shape == target.shape:\n",
        "            pass\n",
        "        elif len(predict.shape) == 4:\n",
        "            target = F.one_hot(target, num_classes=nclass).permute(0, 3, 1, 2).contiguous()\n",
        "        else:\n",
        "            assert 'Predict tensor shape of {} is not assceptable.'.format(predict.shape)\n",
        "\n",
        "        dice = BinaryDiceLoss(**self.kwargs)\n",
        "        total_loss = 0\n",
        "        weight = torch.Tensor([1. / nclass] * nclass).cuda() if self.weight is None else self.weight\n",
        "        predict = F.softmax(predict, dim=1)\n",
        "\n",
        "        for i in range(nclass):\n",
        "            if i != self.ignore_index:\n",
        "                dice_loss = dice(predict[:, i], target[:, i])\n",
        "\n",
        "                assert weight.shape[0] == nclass, \\\n",
        "                    'Expected weight tensor with shape [{}], but got[{}]'.format(nclass, weight.shape[0])\n",
        "                dice_loss *= weight[i]\n",
        "                total_loss += dice_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "class BalancedDiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Dice Loss weighted by inverse of label frequency\n",
        "\n",
        "    Arguments:\n",
        "        ignore_index (int): Class index to ignore\n",
        "        **kwargs: Additional arguments passed to BinaryDiceLoss\n",
        "\n",
        "    Returns:\n",
        "        Loss tensor\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ignore_index=-100, **kwargs):\n",
        "        super(BalancedDiceLoss, self).__init__()\n",
        "        self.kwargs = kwargs\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        class_weights = self.calculate_class_weights(target)\n",
        "\n",
        "        loss_weight = torch.ones(predict.shape[1], device=predict.device) * 0.00001\n",
        "        for i, weight in enumerate(class_weights):\n",
        "            loss_weight[i] = weight\n",
        "\n",
        "        loss = DiceLoss(weight=loss_weight, ignore_index=self.ignore_index, **self.kwargs)\n",
        "\n",
        "        return loss(predict, target)\n",
        "\n",
        "    def calculate_class_weights(self, target):\n",
        "        unique, unique_counts = torch.unique(target[target != self.ignore_index], return_counts=True)\n",
        "        class_ratios = unique_counts.float() / torch.numel(target)\n",
        "        class_weights = 1.0 / class_ratios\n",
        "        class_weights /= torch.sum(1. / class_weights)\n",
        "\n",
        "        return class_weights\n",
        "\n",
        "\n",
        "class DiceCELoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Combination of dice loss and cross entropy loss through summation\n",
        "\n",
        "    Arguments:\n",
        "        loss_weight (Tensor, optional): A manual rescaling weight given to each class.\n",
        "                                        If provided, should be a Tensor of size C\n",
        "        dice_weight (float): Weight on dice loss for the summation, while the weight\n",
        "                             on cross-entropy loss is (1 - dice_weight)\n",
        "        dice_smooth (float, optional): A float number to smooth dice loss and avoid NaN error.\n",
        "                                       Default: 1\n",
        "        dice_p (int, optional): Denominator value: \\sum{x^p} + \\sum{y^p}. Default: 1\n",
        "        ignore_index (int, optional): Class index to ignore. Default: None\n",
        "\n",
        "    Returns:\n",
        "        Loss tensor\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss_weight=None, dice_weight=0.5, dice_smooth=1,\n",
        "                 dice_p=1, ignore_index=-100):\n",
        "\n",
        "        super(DiceCELoss, self).__init__()\n",
        "        self.loss_weight = loss_weight\n",
        "        self.dice_weight = dice_weight\n",
        "        self.dice_smooth = dice_smooth\n",
        "        self.dice_p = dice_p\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "        self.dice_loss = DiceLoss(weight=self.loss_weight, ignore_index=self.ignore_index,\n",
        "                                  smooth=self.dice_smooth, p=self.dice_p)\n",
        "        self.ce_loss = nn.CrossEntropyLoss(weight=self.loss_weight, ignore_index=self.ignore_index)\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        assert predict.shape[0] == target.shape[0], \"predict & target batch size do not match\"\n",
        "\n",
        "        loss = self.dice_weight * self.dice_loss(predict, target) + (1 - self.dice_weight) * self.ce_loss(predict, target)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class BalancedDiceCELoss(nn.Module):\n",
        "    r\"\"\"\n",
        "    Dice Cross Entropy weighted by inverse of label frequency\n",
        "    Arguments:\n",
        "        ignore_index (int): Class index to ignore\n",
        "        predict (torch.tensor): Predicted tensor of shape [N, C, *]\n",
        "        target (torch.tensor): Target tensor either in shape [N,*] or of same shape with predict\n",
        "        other args pass to DiceCELoss, excluding loss_weight\n",
        "    Returns:\n",
        "        Same as DiceCELoss\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ignore_index=-100, **kwargs):\n",
        "        super(BalancedDiceCELoss, self).__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        # get class weights\n",
        "        class_weights = self.calculate_class_weights(target)\n",
        "        loss_weight = torch.ones(predict.shape[1], device=predict.device) * 0.00001\n",
        "\n",
        "        for i, weight in enumerate(class_weights):\n",
        "            loss_weight[i] = weight\n",
        "\n",
        "        loss = DiceCELoss(loss_weight=loss_weight, **self.kwargs)\n",
        "\n",
        "        return loss(predict, target)\n",
        "\n",
        "    def calculate_class_weights(self, target):\n",
        "        unique, unique_counts = torch.unique(target[target != self.ignore_index], return_counts=True)\n",
        "        class_ratios = unique_counts.float() / torch.numel(target)\n",
        "        class_weights = 1.0 / class_ratios\n",
        "        class_weights /= torch.sum(1. / class_weights)\n",
        "\n",
        "        return class_weights"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1gxmM7CqyjTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom Dataset\n",
        "\n",
        "from pathlib import Path\n",
        "import tqdm, re\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "class CropData(Dataset):\n",
        "    r\"\"\"\n",
        "    Create an iterable dataset of image chips\n",
        "    Arguments:\n",
        "        src_dir (str): Path to the folder contains data folders and files.\n",
        "        usage (str): can be either train, validate, or test.\n",
        "        dataset_name (str): Name of the training/validation dataset containing \n",
        "                            structured folders for image, label, and mask.\n",
        "        apply_normalization (binary): decides if normalization should be applied.\n",
        "        trans (list of str): Transformation or data augmentation methods; list \n",
        "                             elements could be chosen from:\n",
        "                             ['v_flip','h_flip','d_flip','rotate','resize']\n",
        "        split_ratio (float): Number in the range (0,1) that decides on the portion \n",
        "                             of samples that should be used for training. \n",
        "                             The remaining portion of samples will be assigned to \n",
        "                             the 'validation' dataset. Default is 0.8.\n",
        "        make_deterministic (Binary): If set to True, we seed the numpy randomization \n",
        "                                     in splitting the dataset into train and validation \n",
        "                                     subfolders.\n",
        "    Returns:\n",
        "        A tuple of (image, label) for training and validation but only the image iterable \n",
        "        if in the inference phase.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, src_dir, usage, dataset_name, split_ratio=0.8, \n",
        "                 apply_normalization=False, trans=None, **kwargs):\n",
        "\n",
        "        self.usage = usage\n",
        "        self.dataset_name = dataset_name\n",
        "        self.split_ratio = split_ratio\n",
        "        self.apply_normalization = apply_normalization\n",
        "        self.trans = trans\n",
        "\n",
        "        assert self.usage in [\"train\", \"validation\", \"inference\"], \"Usage is not recognized.\"\n",
        "\n",
        "        img_fnames = [Path(dirpath) / f \n",
        "                      for (dirpath, dirnames, filenames) in os.walk(Path(src_dir) / self.dataset_name) \n",
        "                      for f in filenames \n",
        "                      if f.endswith(\".tif\") and \"merged\" in f and \"_\".join(f.split(\"_\")[1:3]) in train_ids]\n",
        "        img_fnames.sort()\n",
        "\n",
        "        lbl_fnames = [Path(dirpath) / f \n",
        "                      for (dirpath, dirnames, filenames) in os.walk(Path(src_dir) / self.dataset_name) \n",
        "                      for f in filenames \n",
        "                      if f.endswith(\".tif\") and \"merged\" in f and re.search(r\"_\\d{3}_\\d{3}\", f)]\n",
        "        lbl_fnames.sort()\n",
        "\n",
        "        if self.usage in [\"train\", \"validation\"]:\n",
        "\n",
        "            self.img_chips = []\n",
        "            self.lbl_chips = []\n",
        "\n",
        "            total_samples = len(img_fnames)\n",
        "            indices = np.arange(total_samples)\n",
        "            split_index = int(total_samples * self.split_ratio)\n",
        "\n",
        "            np.random.seed(0)\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            train_indices = indices[:split_index]\n",
        "            val_indices = indices[split_index:]\n",
        "\n",
        "            train_img_fnames = [img_fnames[i] for i in train_indices]\n",
        "            train_lbl_fnames = [lbl_fnames[i] for i in train_indices]\n",
        "\n",
        "            val_img_fnames = [img_fnames[i] for i in val_indices]\n",
        "            val_lbl_fnames = [lbl_fnames[i] for i in val_indices]\n",
        "\n",
        "            if self.usage == \"train\":\n",
        "                img_fnames = train_img_fnames\n",
        "                lbl_fnames = train_lbl_fnames\n",
        "            else:\n",
        "                img_fnames = val_img_fnames\n",
        "                lbl_fnames = val_lbl_fnames\n",
        "\n",
        "            for img_fname, lbl_fname in tqdm.tqdm(zip(img_fnames, lbl_fnames), \n",
        "                                                  total=len(img_fnames)):\n",
        "                    \n",
        "                img_chip = load_data(Path(src_dir) / self.dataset_name / img_fname,\n",
        "                                     apply_normalization=self.apply_normalization, \n",
        "                                     is_label=False)\n",
        "                img_chip = img_chip.transpose((1, 2, 0))\n",
        "\n",
        "                lbl_chip = load_data(Path(src_dir) / self.dataset_name / lbl_fname, \n",
        "                                     is_label=True)\n",
        "\n",
        "                self.img_chips.append(img_chip)\n",
        "                self.lbl_chips.append(lbl_chip)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        print(f\"------ {self.usage} dataset with {len(self.img_chips)} patches created ------\")\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Support indexing such that dataset[index] can be used to get \n",
        "        the (index)th sample.\n",
        "        \"\"\"\n",
        "        if self.usage in [\"train\", \"validation\"]:\n",
        "            img_chip = self.img_chips[index]\n",
        "            lbl_chip = self.lbl_chips[index]\n",
        "\n",
        "            if self.trans and self.usage == \"train\":\n",
        "                trans_flip_ls = [m for m in self.trans if \"flip\" in m]\n",
        "                if random.randint(0, 1) and len(trans_flip_ls) > 1:\n",
        "                    trans_flip = random.sample(trans_flip_ls, 1)\n",
        "                    img_chip, lbl_chip = flip(img_chip, lbl_chip, trans_flip[0])\n",
        "                    \n",
        "                if random.randint(0, 1) and \"resize\" in self.trans:\n",
        "                    scale_factor = kwargs.get(\"scale_factor\", (0.75, 1.5))\n",
        "                    img_chip, lbl_chip = re_scale(img_chip, lbl_chip.astype(np.uint8),\n",
        "                                                  scale=scale_factor, crop_strategy=\"center\")\n",
        "                    \n",
        "                if random.randint(0, 1) and \"rotate\" in self.trans:\n",
        "                    deRotate = kwargs.get(\"rotation_degree\", (-90, 90))\n",
        "                    img_chip, lbl_chip = center_rotate(img_chip, lbl_chip, deRotate)\n",
        "                    \n",
        "                if random.randint(0, 1) and 'shift_brightness' in self.trans:\n",
        "                    bshift_subs = kwargs.get(\"bshift_subs\", (3, 3))\n",
        "                    bshift_gamma_range = kwargs.get(\"bshift_gamma_range\", (0.2, 2.0))\n",
        "                    patch_shift = kwargs.get(\"patch_shift\", True)\n",
        "                    img_chip = shift_brightness(img_chip, gamma_range=bshift_gamma_range,\n",
        "                                                shift_subset=bshift_subs, patch_shift=patch_shift)\n",
        "            \n",
        "            label = torch.from_numpy(np.ascontiguousarray(lbl_chip)).long()\n",
        "            # shape from (H,W,C) --> (C,H,W)\n",
        "            img_chip = torch.from_numpy(img_chip.transpose((2, 0, 1))).float()\n",
        "\n",
        "            return img_chip, label\n",
        "        \n",
        "        else:\n",
        "            img_chip = self.img_chips[index]\n",
        "            img_chip = torch.from_numpy(img_chip.transpose((2, 0, 1))).float()\n",
        "\n",
        "            return img_chip\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_chips)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "900t5IAv0WO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title training and validation functions\n",
        "\n",
        "def train_one_epoch(trainData, model, criterion, optimizer, scheduler, lr_policy, device, train_loss=[]):\n",
        "    r\"\"\"\n",
        "    Train the model.\n",
        "    Arguments:\n",
        "            trainData (DataLoader object) -- Batches of image chips from PyTorch custom dataset(AquacultureData)\n",
        "            model (initialized model) -- Choice of segmentation Model to train.\n",
        "            criterion -- Chosen function to calculate loss over training samples.\n",
        "            optimizer -- Chosen function for optimization.\n",
        "            scheduler -- Update policy for learning rate decay.\n",
        "            lr_policy (str) -- Learning rate decade policy.\n",
        "            device --(str) Either 'cuda' or 'cpu'.\n",
        "            train_loss -- (empty list) To record average training loss for each epoch.\n",
        "            \n",
        "    \"\"\"\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    num_train_batches = len(trainData)\n",
        "\n",
        "    for img_chips, labels in trainData:\n",
        "\n",
        "        img = img_chips.to(device)\n",
        "        label = labels.to(device)\n",
        "\n",
        "        model_out = model(img)\n",
        "\n",
        "        loss = eval(criterion)(model_out, label)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if lr_policy == \"CyclicLR\":\n",
        "            scheduler.step()\n",
        "\n",
        "    print('train loss:{}'.format(epoch_loss / num_train_batches))\n",
        "\n",
        "    if lr_policy == \"CyclicLR\":\n",
        "        print(\"LR: {}\".format(scheduler.get_last_lr()))\n",
        "\n",
        "    if train_loss is not None:\n",
        "        train_loss.append(float(epoch_loss / num_train_batches))\n",
        "\n",
        "\n",
        "def validate_one_epoch(valData, model, criterion, device, val_loss=[]):\n",
        "    \"\"\"\n",
        "        Evaluate the model on separate Landsat scenes.\n",
        "        Params:\n",
        "            valData (DataLoader object) -- Batches of image chips from PyTorch custom dataset(AquacultureData)\n",
        "            model -- Choice of segmentation Model.\n",
        "            criterion -- Chosen function to calculate loss over validation samples.\n",
        "            device (str): Either 'cuda' or 'cpu'.\n",
        "            val_loss (empty list): To record average loss for each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # mini batch iteration\n",
        "    eval_epoch_loss = 0\n",
        "    num_val_batches = len(valData)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for img_chips, labels in valData:\n",
        "            \n",
        "            img = img_chips.to(device)\n",
        "            label = labels.to(device)\n",
        "\n",
        "            pred = model(img)\n",
        "\n",
        "            loss = eval(criterion)(pred, label)\n",
        "            eval_epoch_loss += loss.item()\n",
        "\n",
        "    print('validation loss: {:.4f}'.format(eval_epoch_loss / num_val_batches))\n",
        "\n",
        "    if val_loss is not None:\n",
        "        val_loss.append(float(eval_epoch_loss / num_val_batches))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rc-aeeT_zdGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Accuracy Metrics Assessment\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BinaryMetrics:\n",
        "    \"\"\"\n",
        "    Metrics measuring model performance.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ref_array, score_array, pred_array=None):\n",
        "        \"\"\"\n",
        "        Params:\n",
        "            ref_array (ndarray): Array of ground truth\n",
        "            score_array (ndarray): Array of pixels scores of positive class\n",
        "            pred_array (ndarray): Boolean array of predictions telling whether\n",
        "                                 a pixel belongs to a specific class.\n",
        "        \"\"\"\n",
        "\n",
        "        self.tp = None\n",
        "        self.fp = None\n",
        "        self.fn = None\n",
        "        self.tn = None\n",
        "        self.eps = 10e-6\n",
        "        self.observation = ref_array.flatten()\n",
        "        self.score = score_array.flatten()\n",
        "        if pred_array is not None:\n",
        "            self.prediction = pred_array.flatten()\n",
        "        # take score over 0.5 as prediction if predArray not provided\n",
        "        else:\n",
        "            self.prediction = np.where(self.score > 0.5, 1, 0)\n",
        "        self.confusion_matrix = self.confusion_matrix()\n",
        "\n",
        "        assert self.observation.shape == self.score.shape, \"Inconsistent input shapes\"\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"\n",
        "        Add two BinaryMetrics instances\n",
        "        Params:\n",
        "            other (''BinaryMetrics''): A BinaryMetrics instance\n",
        "        Return:\n",
        "            ''BinaryMetrics''\n",
        "        \"\"\"\n",
        "\n",
        "        return BinaryMetrics(np.append(self.observation, other.observation),\n",
        "                             np.append(self.score, other.score),\n",
        "                             np.append(self.prediction, other.prediction))\n",
        "\n",
        "    def __radd__(self, other):\n",
        "        \"\"\"\n",
        "        Add a BinaryMetrics instance with reversed operands\n",
        "        Params:\n",
        "            other\n",
        "        Returns:\n",
        "            ''BinaryMetrics\n",
        "        \"\"\"\n",
        "\n",
        "        if other == 0:\n",
        "            return self\n",
        "        else:\n",
        "            return self.__add__(other)\n",
        "\n",
        "    def confusion_matrix(self):\n",
        "        \"\"\"\n",
        "        Calculate confusion matrix of given ground truth and predicted label\n",
        "        Returns:\n",
        "            \"pandas.dataframe\" of observation on the column and prediction on the row\n",
        "        \"\"\"\n",
        "\n",
        "        ref_array = self.observation\n",
        "        pred_array = self.prediction\n",
        "\n",
        "        if ref_array.max() > 1 or pred_array.max() > 1:\n",
        "            raise Exception(\"Invalid array\")\n",
        "        predArray = pred_array * 2\n",
        "        sub = ref_array - predArray\n",
        "\n",
        "        self.tp = np.sum(sub == -1)\n",
        "        self.fp = np.sum(sub == -2)\n",
        "        self.fn = np.sum(sub == 1)\n",
        "        self.tn = np.sum(sub == 0)\n",
        "\n",
        "        confusionMatrix = pd.DataFrame(data=np.array([[self.tn, self.fp], [self.fn, self.tp]]),\n",
        "                                       index=['observation = 0', 'observation = 1'],\n",
        "                                       columns=['prediction = 0', 'prediction = 1'])\n",
        "        return confusionMatrix\n",
        "\n",
        "    def ir(self):\n",
        "        \"\"\"\n",
        "        Imbalance Ratio (IR) is defined as the proportion between positive and negative\n",
        "        instances of the label. This value lies within the [0, ∞] range, having a value\n",
        "        IR = 1 in the balanced case.\n",
        "        Returns:\n",
        "                float\n",
        "        \"\"\"\n",
        "        try:\n",
        "            ir = (self.tp + self.fn) / (self.fp + self.tn)\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            ir = (self.tp + self.fn) / (self.fp + self.tn + self.eps)\n",
        "\n",
        "        return ir\n",
        "\n",
        "    def accuracy(self):\n",
        "        \"\"\"\n",
        "        Calculate Overall (Global) Accuracy.\n",
        "        Returns:\n",
        "            float scalar\n",
        "        \"\"\"\n",
        "        try:\n",
        "            oa = (self.tp + self.tn) / (self.tp + self.tn + self.fp + self.fn)\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            oa = (self.tp + self.tn) / (self.tp + self.tn + self.fp + self.fn + self.eps)\n",
        "\n",
        "        return oa\n",
        "\n",
        "    def precision(self):\n",
        "        \"\"\"\n",
        "        Calculate User’s Accuracy (Positive Prediction Value (PPV) | UA).\n",
        "        Returns:\n",
        "            float\n",
        "        \"\"\"\n",
        "        try:\n",
        "            ua = self.tp / (self.tp + self.fp)\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            ua = self.tp / (self.tp + self.fp + self.eps)\n",
        "\n",
        "        return ua\n",
        "\n",
        "    def recall(self):\n",
        "        \"\"\"\n",
        "        Calculate Producer's Accuracy (True Positive Rate |Sensitivity |hit rate | recall).\n",
        "        Returns:\n",
        "            float\n",
        "        \"\"\"\n",
        "        try:\n",
        "            pa = self.tp / (self.tp + self.fn)\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            pa = self.tp / (self.tp + self.fn + self.eps)\n",
        "\n",
        "        return pa\n",
        "\n",
        "    def false_positive_rate(self):\n",
        "        \"\"\"\n",
        "        Calculate False Positive Rate(FPR) aka. False Alarm Rate (FAR), or Fallout.\n",
        "        Returns:\n",
        "             float\n",
        "        \"\"\"\n",
        "        try:\n",
        "            fpr = self.fp / (self.tn + self.fp)\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            fpr = self.fp / (self.tn + self.fp + self.eps)\n",
        "\n",
        "        return fpr\n",
        "\n",
        "    def iou(self):\n",
        "        \"\"\"\n",
        "        Calculate interception over union for the positive class.\n",
        "        Returns:\n",
        "            float\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            iou = self.tp / (self.tp + self.fp + self.fn)\n",
        "        except ZeroDivisionError:\n",
        "            iou = self.tp / (self.tp + self.fp + self.fn + self.eps)\n",
        "\n",
        "        return iou\n",
        "\n",
        "    def f1_measure(self):\n",
        "        \"\"\"\n",
        "        Calculate F1 score.\n",
        "        Returns:\n",
        "            float\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            precision = self.tp / (self.tp + self.fp)\n",
        "            recall = self.tp / (self.tp + self.fn)\n",
        "            f1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "        except ZeroDivisionError:\n",
        "            precision = self.tp / (self.tp + self.fp + self.eps)\n",
        "            recall = self.tp / (self.tp + self.fn + self.eps)\n",
        "            f1 = (2 * precision * recall) / (precision + recall + self.eps)\n",
        "\n",
        "        return f1\n",
        "\n",
        "    def tss(self):\n",
        "        \"\"\"\n",
        "        Calculate true skill statistic (TSS)\n",
        "        Returns:\n",
        "            float\n",
        "        \"\"\"\n",
        "\n",
        "        return self.tp / (self.tp + self.fn) + self.tn / (self.tn + self.fp) - 1\n",
        "\n",
        "\n",
        "def do_accuracy_evaluation(eval_data, model, filename, gpu=True):\n",
        "    r\"\"\"\n",
        "    Evaluate the model on a separate Landsat scene.\n",
        "\n",
        "    Arguments:\n",
        "    eval_data -- Batches of image chips from PyTorch custom dataset(AquacultureData)\n",
        "    model -- Choice of segmentation Model to train.\n",
        "    filename -- (str) Name of the csv file to report metrics.\n",
        "    gpu --(binary) If False the model will run on CPU instead of GPU. Default is True.\n",
        "\n",
        "    Note: to harden the class prediction around a higher probability, drop 'class_pred' argument\n",
        "          and increase the threshold of 'predArray' in the 'BinaryMetrics' class '__init__' function.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    metrics_ls = []\n",
        "\n",
        "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for img_chips, label in eval_data:\n",
        "\n",
        "        img = Variable(img_chips, requires_grad=False)  # size: batch size X channels X W X H\n",
        "        label = Variable(label, requires_grad=False)  # size: batch size X W X H\n",
        "\n",
        "        if gpu:\n",
        "            img = img.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        pred = model(img)  # size: batch size x number of categories X W x H\n",
        "        pred_prob = F.softmax(pred, 1)\n",
        "        batch, n_class, height, width = pred_prob.size()\n",
        "\n",
        "        for i in range(batch):\n",
        "            label_batch = label[i, :, :].cpu().numpy()\n",
        "            batch_pred = pred_prob.max(dim=1)[1][:, :, :].data[i].cpu().numpy()\n",
        "\n",
        "            for n in range(1, n_class):\n",
        "                class_prob = pred_prob[:, n, :, :].data[i].cpu().numpy()\n",
        "                class_pred = np.where(batch_pred == n, 1, 0)\n",
        "                class_label = np.where(label_batch == n, 1, 0)\n",
        "                chip_metrics = BinaryMetrics(class_label, class_prob, class_pred)\n",
        "\n",
        "                try:\n",
        "                    metrics_ls[n - 1].append(chip_metrics)\n",
        "                except:\n",
        "                    metrics_ls.append([chip_metrics])\n",
        "\n",
        "    metrics = [sum(m) for m in metrics_ls]\n",
        "\n",
        "    report = pd.DataFrame({\n",
        "        \"Imbalance Ratio\": [m.ir() for m in metrics],\n",
        "        \"Overall Accuracy\": [m.accuracy() for m in metrics],\n",
        "        \"Precision (UA or PPV)\": [m.precision() for m in metrics],\n",
        "        \"Recall (PA or TPR or Sensitivity)\": [m.recall() for m in metrics],\n",
        "        \"False Positive Rate\": [m.false_positive_rate() for m in metrics],\n",
        "        \"IoU\": [m.iou() for m in metrics],\n",
        "        \"F1-score\": [m.f1_measure() for m in metrics],\n",
        "        \"TSS\": [m.tss() for m in metrics]\n",
        "    }, [\"class_{}\".format(m) for m in range(1, len(metrics) + 1)])\n",
        "\n",
        "    report.to_csv(filename, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tq7P5Dhn_BJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Compiler\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.nn import init\n",
        "\n",
        "\n",
        "def get_optimizer(optimizer, params, lr, momentum):\n",
        "    \"\"\"\n",
        "    Get an instance of the specified optimizer with the given parameters.\n",
        "\n",
        "    Parameters:\n",
        "        optimizer (str): The name of the optimizer. Options: \n",
        "                              \"sgd\", \"nesterov\", \"adam\", \"amsgrad\".\n",
        "        params (iterable): The parameters to optimize.\n",
        "        lr (float): The learning rate.\n",
        "        momentum (float): The momentum factor for optimizers that support it.\n",
        "\n",
        "    Returns:\n",
        "        torch.optim.Optimizer: An instance of the specified optimizer with the \n",
        "        given parameters.\n",
        "    \"\"\"\n",
        "    optimizer = optimizer.lower()\n",
        "\n",
        "    if optimizer == \"sgd\":\n",
        "        return torch.optim.SGD(params, lr, momentum=momentum)\n",
        "    elif optimizer == \"nesterov\":\n",
        "        return torch.optim.SGD(params, lr, momentum=momentum, nesterov=True)\n",
        "    elif optimizer == \"adam\":\n",
        "        return torch.optim.Adam(params, lr)\n",
        "    elif optimizer == 'amsgrad':\n",
        "        return torch.optim.Adam(params, lr, amsgrad=True)\n",
        "    else:\n",
        "        raise ValueError(f\"{optimizer} currently not supported, please choose a valid optimizer\")\n",
        "\n",
        "\n",
        "def init_weights(model, init_type=\"normal\", gain=0.02):\n",
        "    \"\"\"Initialize the network weights using various initialization methods.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The initialized model.\n",
        "        init_type (str): The initialization type. Supported initialization methods: \n",
        "                         \"normal\", \"xavier\", \"kaiming\", \"orthogonal\"\n",
        "                         Default is \"normal\" for random initialization\n",
        "                         using a normal distribution.\n",
        "        gain (float): The scaling factor for the initialized weights.\n",
        "    \"\"\"\n",
        "    class_name = model.__class__.__name__\n",
        "    if hasattr(model, \"weight\") and (class_name.find(\"Conv\") != -1 or \n",
        "                                     class_name.find(\"Linear\") != -1):\n",
        "        if init_type == \"normal\":\n",
        "            init.normal_(model.weight.data, 0.0, gain)\n",
        "        elif init_type == \"xavier\":\n",
        "            init.xavier_normal_(model.weight.data, gain=gain)\n",
        "        elif init_type == \"kaiming\":\n",
        "            init.kaiming_normal_(model.weight.data, a=0, mode=\"fan_out\")\n",
        "        elif init_type == \"orthogonal\":\n",
        "            init.orthogonal_(model.weight.data, gain=gain)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"initialization method {init_type} is not implemented.\")\n",
        "\n",
        "    if hasattr(model, \"bias\") and model.bias is not None:\n",
        "        init.constant_(model.bias.data, 0.0)\n",
        "\n",
        "    if class_name.find(\"BatchNorm2d\") != -1:\n",
        "        init.normal_(model.weight.data, 1.0, gain)\n",
        "        init.constant_(model.bias.data, 0.0)\n",
        "\n",
        "    print(f\"initialize network with {init_type}.\")\n",
        "\n",
        "\n",
        "class PolynomialLR(_LRScheduler):\n",
        "    \"\"\"Polynomial learning rate decay until the step reaches the max_decay_steps.\n",
        "\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        max_decay_steps (int): The maximum number of steps after which the learning \n",
        "                               rate stops decreasing.\n",
        "        min_learning_rate (float): The minimum value of the learning rate. \n",
        "                                   Learning rate decay stops at this value.\n",
        "        power (float): The power of the polynomial.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, max_decay_steps, min_learning_rate=1e-5, power=1.0):\n",
        "\n",
        "        if max_decay_steps <= 1.:\n",
        "            raise ValueError('max_decay_steps should be greater than 1.')\n",
        "\n",
        "        self.max_decay_steps = max_decay_steps\n",
        "        self.min_learning_rate = min_learning_rate\n",
        "        self.power = power\n",
        "        self.last_step = 0\n",
        "\n",
        "        super().__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.last_step > self.max_decay_steps:\n",
        "            return [self.min_learning_rate for _ in self.base_lrs]\n",
        "\n",
        "        return [(base_lr - self.min_learning_rate) *\n",
        "                ((1 - self.last_step / self.max_decay_steps) ** self.power) +\n",
        "                self.min_learning_rate for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, step=None):\n",
        "\n",
        "        if step is None:\n",
        "            step = self.last_step + 1\n",
        "        self.last_step = step if step != 0 else 1\n",
        "\n",
        "        if self.last_step <= self.max_decay_steps:\n",
        "            decay_lrs = [(base_lr - self.min_learning_rate) *\n",
        "                         ((1 - self.last_step / self.max_decay_steps) ** self.power) +\n",
        "                         self.min_learning_rate for base_lr in self.base_lrs]\n",
        "\n",
        "            for param_group, lr in zip(self.optimizer.param_groups, decay_lrs):\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "\n",
        "class ModelCompiler:\n",
        "\n",
        "    def __init__(self, model, working_dir, out_dir, num_classes, inch, gpu_devices=[0],\n",
        "                 model_init_type=\"kaiming\", params_init=None, freeze_params=None):\n",
        "        r\"\"\"\n",
        "        Train the model.\n",
        "\n",
        "        Arguments:\n",
        "            model (ordered Dict) -- initialized model either vanilla or pre-trained depending on\n",
        "                                    the argument 'params_init'.\n",
        "            working_dir (str) -- General Directory to store output from any experiment.\n",
        "            out_dir (str) -- specific output directory for the current experiment.\n",
        "            num_classes (int) -- number of output classes based on the classification scheme.\n",
        "            inch (int) -- number of input channels.\n",
        "            gpu_devices (list) -- list of GPU indices to use for parallelism if multiple GPUs are available.\n",
        "                                  Default is set to index 0 for a single GPU.\n",
        "            model_init_type -- (str) model initialization choice if it's not pre-trained.\n",
        "            params_init --(str or None) Path to the saved model parameters. If set to 'None', a vanilla model will\n",
        "                          be initialized.\n",
        "            freeze_params (list) -- list of integers that show the index of layers in a pre-trained\n",
        "                                    model (on the source domain) that we want to freeze for fine-tuning\n",
        "                                    the model on the target domain used in the model-based transfer learning.\n",
        "        \"\"\"\n",
        "\n",
        "        self.working_dir = working_dir\n",
        "        self.out_dir = out_dir\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.inch = inch\n",
        "        self.gpu_devices = gpu_devices\n",
        "        self.use_sync_bn = use_sync_bn\n",
        "        self.model_init_type = model_init_type\n",
        "        self.params_init = params_init\n",
        "        self.checkpoint_dirpath = None\n",
        "\n",
        "        self.model = model\n",
        "        self.model_name = self.model.__class__.__name__\n",
        "\n",
        "        if self.params_init:\n",
        "            self.load_params(self.params_init, freeze_params)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        if self.device.type == \"cuda\":\n",
        "            print(\"----------GPU available----------\")\n",
        "            if self.gpu_devices:\n",
        "                torch.cuda.set_device(self.gpu_devices[0])\n",
        "                self.model = torch.nn.DataParallel(self.model, device_ids=self.gpu_devices)\n",
        "        else:\n",
        "            print('----------No GPU available, using CPU instead----------')\n",
        "            self.model = self.model.to(device)\n",
        "\n",
        "\n",
        "        if params_init is None:\n",
        "            init_weights(self.model, self.model_init_type, gain=0.01)\n",
        "\n",
        "        num_params = sum([p.numel() for p in self.model.parameters() if p.requires_grad])\n",
        "        print(\"total number of trainable parameters: {:2.1f}M\".format(num_params / 1000000))\n",
        "\n",
        "        if self.params_init:\n",
        "            print(\"---------- Pre-trained model compiled successfully ----------\")\n",
        "        else:\n",
        "            print(\"---------- Vanilla Model compiled successfully ----------\")\n",
        "\n",
        "    def load_params(self, dir_params, freeze_params):\n",
        "        \"\"\"\n",
        "        Load parameters from a file and update the model's state dictionary.\n",
        "\n",
        "        Args:\n",
        "            dir_params (str): Directory path to the parameters file.\n",
        "            freeze_params (list): List of indices corresponding to the model's parameters that should be frozen.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # inparams = torch.load(self.params_init, map_location='cuda:0')\n",
        "        inparams = torch.load(self.params_init)\n",
        "\n",
        "        model_dict = self.model.state_dict()\n",
        "\n",
        "        if \"module\" in list(inparams.keys())[0]:\n",
        "            inparams_filter = {k[7:]: v.cpu() for k, v in inparams.items() if k[7:] in model_dict}\n",
        "        else:\n",
        "            inparams_filter = {k: v.cpu() for k, v in inparams.items() if k in model_dict}\n",
        "\n",
        "        model_dict.update(inparams_filter)\n",
        "\n",
        "        # load new state dict\n",
        "        self.model.load_state_dict(model_dict)\n",
        "\n",
        "        if freeze_params:\n",
        "            for i, p in enumerate(self.model.parameters()):\n",
        "                if i in freeze_params:\n",
        "                    p.requires_grad = False\n",
        "\n",
        "    def fit(self, trainDataset, valDataset, epochs, optimizer_name, lr_init, \n",
        "            lr_policy, criterion, momentum=None, resume=False, resume_epoch=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Train the model on the provided datasets.\n",
        "\n",
        "        Args:\n",
        "            trainDataset: The loaded training dataset.\n",
        "            valDataset: The loaded validation dataset.\n",
        "            epochs (int): The number of epochs to train.\n",
        "            optimizer_name (str): The name of the optimizer to use.\n",
        "            lr_init (float): The initial learning rate.\n",
        "            lr_policy (str): The learning rate policy.\n",
        "            criterion: The loss criterion.\n",
        "            momentum (float, optional): The momentum factor for the optimizer (default: None).\n",
        "            resume (bool, optional): Whether to resume training from a checkpoint (default: False).\n",
        "            resume_epoch (int, optional): The epoch from which to resume training (default: None).\n",
        "            **kwargs: Additional arguments specific to certain learning rate policies.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        # Set the folder to save results.\n",
        "        working_dir = self.working_dir\n",
        "        out_dir = self.out_dir\n",
        "        model_dir = \"{}/{}/{}_ep{}\".format(working_dir, out_dir, self.model_name, epochs)\n",
        "\n",
        "        if not os.path.exists(Path(working_dir) / out_dir / model_dir):\n",
        "            os.makedirs(Path(working_dir) / out_dir / model_dir)\n",
        "\n",
        "        self.checkpoint_dirpath = Path(working_dir) / out_dir / model_dir / \"chkpt\"\n",
        "        if not os.path.exists(self.checkpoint_dirpath):\n",
        "            os.makedirs(self.checkpoint_dirpath)\n",
        "\n",
        "        os.chdir(Path(working_dir) / out_dir / model_dir)\n",
        "\n",
        "        print(\"-------------------------- Start training --------------------------\")\n",
        "        start = datetime.now()\n",
        "\n",
        "        writer = SummaryWriter('../')\n",
        "        lr = lr_init\n",
        "\n",
        "        optimizer = get_optimizer(optimizer_name,\n",
        "                                  filter(lambda p: p.requires_grad, self.model.parameters()),\n",
        "                                  lr,\n",
        "                                  momentum)\n",
        "\n",
        "        # Initialize the learning rate scheduler\n",
        "        if lr_policy == \"StepLR\":\n",
        "            step_size = kwargs.get(\"step_size\", 3)\n",
        "            gamma = kwargs.get(\"gamma\", 0.98)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                  step_size=step_size,\n",
        "                                                  gamma=gamma)\n",
        "\n",
        "        elif lr_policy == \"MultiStepLR\":\n",
        "            milestones = kwargs.get(\"milestones\", [5, 10, 20, 35, 50, 70, 90])\n",
        "            gamma = kwargs.get(\"gamma\", 0.5)\n",
        "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                       milestones=milestones,\n",
        "                                                       gamma=gamma)\n",
        "\n",
        "        elif lr_policy == \"ReduceLROnPlateau\":\n",
        "            mode = kwargs.get(\"mode\", \"min\")\n",
        "            factor = kwargs.get(\"factor\", 0.8)\n",
        "            patience = kwargs.get(\"patience\", 3)\n",
        "            threshold = kwargs.get(\"threshold\", 0.0001)\n",
        "            threshold_mode = kwargs.get(\"threshold_mode\", \"rel\")\n",
        "            min_lr = kwargs.get(\"min_lr\", 3e-6)\n",
        "            verbose = kwargs.get(\"verbose\", True)\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                             mode=mode,\n",
        "                                                             factor=factor,\n",
        "                                                             patience=patience,\n",
        "                                                             threshold=threshold,\n",
        "                                                             threshold_mode=threshold_mode,\n",
        "                                                             min_lr=min_lr,\n",
        "                                                             verbose=verbose)\n",
        "\n",
        "        elif lr_policy == \"PolynomialLR\":\n",
        "            max_decay_steps = kwargs.get(\"max_decay_steps\", 75)\n",
        "            min_learning_rate = kwargs.get(\"min_learning_rate\", 1e-5)\n",
        "            power = kwargs.get(\"power\", 0.8)\n",
        "            scheduler = PolynomialLR(optimizer,\n",
        "                                     max_decay_steps=max_decay_steps,\n",
        "                                     min_learning_rate=min_learning_rate,\n",
        "                                     power=power)\n",
        "\n",
        "        elif lr_policy == \"CyclicLR\":\n",
        "            base_lr = kwargs.get(\"base_lr\", 3e-5)\n",
        "            max_lr = kwargs.get(\"max_lr\", 0.01)\n",
        "            step_size_up = kwargs.get(\"step_size_up\", 1100)\n",
        "            mode = kwargs.get(\"mode\", \"triangular\")\n",
        "            scheduler = optim.lr_scheduler.CyclicLR(optimizer,\n",
        "                                                    base_lr=base_lr,\n",
        "                                                    max_lr=max_lr,\n",
        "                                                    step_size_up=step_size_up,\n",
        "                                                    mode=mode)\n",
        "\n",
        "        else:\n",
        "            scheduler = None\n",
        "\n",
        "        # Resume the model from the specified checkpoint in the config file.\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        if resume:\n",
        "            model_state_file = os.path.join(self.checkpoint_dirpath, \"{}_checkpoint.pth.tar\".format(resume_epoch))\n",
        "            if os.path.isfile(model_state_file):\n",
        "                checkpoint = torch.load(model_state_file)\n",
        "                resume_epoch = checkpoint[\"epoch\"]\n",
        "                scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
        "                self.model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "                optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "                train_loss = checkpoint[\"train loss\"]\n",
        "                val_loss = checkpoint[\"Evaluation loss\"]\n",
        "\n",
        "        # epoch iteration\n",
        "        if resume:\n",
        "            iterable = range(resume_epoch, epochs)\n",
        "        else:\n",
        "            iterable = range(epochs)\n",
        "\n",
        "        for t in iterable:\n",
        "\n",
        "            print(\"Epoch [{}/{}]\".format(t + 1, epochs))\n",
        "\n",
        "            start_epoch = datetime.now()\n",
        "\n",
        "            train_one_epoch(trainDataset, self.model, criterion, optimizer, \n",
        "                            scheduler, lr_policy, device=self.device, \n",
        "                            train_loss=train_loss)\n",
        "            validate_one_epoch(valDataset, self.model, criterion, device=self.device, \n",
        "                               val_loss=val_loss)\n",
        "\n",
        "            # Update the scheduler\n",
        "            if lr_policy in [\"StepLR\", \"MultiStepLR\"]:\n",
        "                scheduler.step()\n",
        "                print(\"LR: {}\".format(scheduler.get_last_lr()))\n",
        "\n",
        "            if lr_policy == \"ReduceLROnPlateau\":\n",
        "                scheduler.step(val_loss[t])\n",
        "\n",
        "            if lr_policy == \"PolynomialLR\":\n",
        "                scheduler.step(t)\n",
        "                print(\"LR: {}\".format(optimizer.param_groups[0]['lr']))\n",
        "\n",
        "            print('time:', (datetime.now() - start_epoch).seconds)\n",
        "\n",
        "            # Adjust logger to resume status and save checkpoints in defined intervals.\n",
        "            checkpoint_interval = 20\n",
        "\n",
        "            writer.add_scalars(\"Loss\",\n",
        "                               {\"train loss\": train_loss[t],\n",
        "                                \"Evaluation loss\": val_loss[t]},\n",
        "                               t + 1)\n",
        "\n",
        "            if (t + 1) % checkpoint_interval == 0:\n",
        "                torch.save({\"epoch\": t + 1,\n",
        "                            \"state_dict\": self.model.state_dict() if len(self.gpu_devices) > 1 else \\\n",
        "                                self.model.module.state_dict(),\n",
        "                            \"scheduler\": scheduler.state_dict(),\n",
        "                            \"optimizer\": optimizer.state_dict(),\n",
        "                            \"train loss\": train_loss,\n",
        "                            \"Evaluation loss\": val_loss},\n",
        "                           os.path.join(self.checkpoint_dirpath, f\"{t + 1}_checkpoint.pth.tar\"))\n",
        "\n",
        "        writer.close()\n",
        "\n",
        "        duration_in_sec = (datetime.now() - start).seconds\n",
        "        duration_format = str(timedelta(seconds=duration_in_sec))\n",
        "        print(f\"----------- Training finished in {duration_format} -----------\")\n",
        "\n",
        "    def accuracy_evaluation(self, evalDataset, filename):\n",
        "        \"\"\"\n",
        "        Evaluate the accuracy of the model on the provided evaluation dataset.\n",
        "\n",
        "        Args:\n",
        "            evalDataset (DataLoader): The evaluation dataset to evaluate the model on.\n",
        "            filename (str): The filename to save the evaluation results in the output CSV.\n",
        "    \"\"\"\n",
        "\n",
        "        if not os.path.exists(Path(self.working_dir) / self.out_dir):\n",
        "            os.makedirs(Path(self.working_dir) / self.out_dir)\n",
        "\n",
        "        os.chdir(Path(self.working_dir) / self.out_dir)\n",
        "\n",
        "        print(\"---------------- Start evaluation ----------------\")\n",
        "\n",
        "        start = datetime.now()\n",
        "\n",
        "        do_accuracy_evaluation(evalDataset, self.model, filename, self.gpu)\n",
        "\n",
        "        duration_in_sec = (datetime.now() - start).seconds\n",
        "        print(\n",
        "            f\"---------------- Evaluation finished in {duration_in_sec}s ----------------\")\n",
        "\n",
        "\n",
        "    def save(self, save_object=\"params\"):\n",
        "        \"\"\"\n",
        "        Save model parameters or the entire model to disk.\n",
        "\n",
        "        Args:\n",
        "            save_object (str): Specifies whether to save \"params\" or \"model\". \n",
        "            Defaults to \"params\".\n",
        "        \"\"\"\n",
        "\n",
        "        if save_object == \"params\":\n",
        "            if len(self.gpu_devices) > 1:\n",
        "                torch.save(self.model.module.state_dict(),\n",
        "                           os.path.join(self.checkpoint_dirpath, \"{}_final_state.pth\".format(self.model_name)))\n",
        "            else:\n",
        "                torch.save(self.model.state_dict(),\n",
        "                           os.path.join(self.checkpoint_dirpath, \"{}_final_state.pth\".format(self.model_name)))\n",
        "\n",
        "            print(\"--------------------- Model parameters is saved to disk ---------------------\")\n",
        "\n",
        "        elif save_object == \"model\":\n",
        "            torch.save(self.model,\n",
        "                       os.path.join(self.checkpoint_dirpath, \"{}_final_state.pth\".format(self.model_name)))\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Improper object type.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ihbYgoxnLCNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Calls**"
      ],
      "metadata": {
        "id": "uJcafTT2_w1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \n",
        "    # Custom dataset params\n",
        "    \"src_dir\": \"/content/gdrive/MyDrive/PondDataset\",\n",
        "    \"train_dataset_name\": \"chips_binary_filtered\",\n",
        "    \"split_ratio\": 0.8,\n",
        "    \"apply_normalization\": True,\n",
        "    \"transformations\": [\"v_flip\",\"h_flip\",\"d_flip\", \"rotate\", \"resize\"],\n",
        "    \"aug_prams\": {\n",
        "        \"scale_factor\": (0.75, 1.3), \n",
        "        \"rotation_degree\": (-90, 90), \n",
        "        \"bshift_gamma_range\": (0.2, 2), \n",
        "        \"bshift_subs\": (3, 3), \n",
        "        \"patch_shift\": True\n",
        "    },\n",
        "\n",
        "    # DataLoader\n",
        "    \"train_BatchSize\": 16,\n",
        "    \"val_test_BatchSize\": 1,\n",
        "\n",
        "    # model initialization params\n",
        "    \"n_classes\": 2,\n",
        "    \"input_channels\": 4,\n",
        "\n",
        "    # Model compiler params\n",
        "    \"working_dir\": \"\",\n",
        "    \"n_classes\": 2,\n",
        "    \"gpuDevices\": [0],\n",
        "    \"init_type\": \"kaiming\",\n",
        "    \"params_init\": None,\n",
        "    \"freeze_params\": None,\n",
        "    \n",
        "    # Model fitting\n",
        "    \"epochs\": 100,\n",
        "    \"optimizer\": \"SGD\",\n",
        "    \"LR\": 0.003,\n",
        "    \"LR_policy\": \"PolynomialLR\",\n",
        "    \"criterion\": BalancedTverskyFocalCELoss,\n",
        "    \"momentum\": 0.95,\n",
        "    \"resume\": False,\n",
        "    \"resume_epoch\": None,\n",
        "    \"lr_prams\": {\n",
        "        # StepLR & MultiStepLR\n",
        "        \"step_size\" : 3,\n",
        "        \"milestones\": [5, 10, 20, 35, 50, 70, 90], \n",
        "        \"gamma\": 0.98, \n",
        "        # ReduceLROnPlateau\n",
        "        \"mode\": \"min\", \n",
        "        \"factor\": 0.8, \n",
        "        \"patience\": 3, \n",
        "        \"threshold\": 0.0001,\n",
        "        \"threshold_mode\": \"rel\",\n",
        "        \"min_lr\": 3e-6,\n",
        "        # PolynomialLR\n",
        "        \"max_decay_steps\": 75,\n",
        "        \"min_learning_rate\": 1e-5,\n",
        "        \"power\": 0.8,\n",
        "        # CyclicLR\n",
        "        \"base_lr\": 3e-5,\n",
        "        \"max_lr\": 0.01,\n",
        "        \"step_size_up\": 1100,\n",
        "        \"mode\": \"triangular\",\n",
        "    },\n",
        "    \n",
        "    # Model accuracy evaluation\n",
        "    \"val_metric_fname\" : \"validate_metrics.csv\",   \n",
        "}\n",
        "\n",
        "if not os.path.exists(config[\"working_dir\"]):\n",
        "    os.makedirs(config[\"working_dir\"])\n",
        "os.chdir(config[\"working_dir\"])"
      ],
      "metadata": {
        "id": "CWU9hoYSHJy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CropData(src_dir = config[\"src_dir\"],\n",
        "                         usage = \"train\",\n",
        "                         dataset_name = config[\"train_dataset_name\"],\n",
        "                         split_ratio = config[\"split_ratio\"],\n",
        "                         apply_normalization = config[\"apply_normalization\"],\n",
        "                         trans = config[\"transformations\"], \n",
        "                         aug_params = config[\"aug_params\"])"
      ],
      "metadata": {
        "id": "H11LNxFR_1ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size = config[\"train_BatchSize\"], \n",
        "                          shuffle = True)"
      ],
      "metadata": {
        "id": "7KiiQe0mBydO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = CropData(src_dir = config[\"src_dir\"],\n",
        "                       usage = \"validation\",\n",
        "                       dataset_name = config[\"train_dataset_name\"],\n",
        "                       split_ratio = config[\"split_ratio\"],\n",
        "                       apply_normalization = config[\"apply_normalization\"])"
      ],
      "metadata": {
        "id": "1-ZRMNmsB4Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_dataset, \n",
        "                        batch_size = config[\"val_test_BatchSize\"], \n",
        "                        shuffle = False)"
      ],
      "metadata": {
        "id": "1GPq1iIQ51mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Unet(n_classes=config[\"n_classes\"], in_channels=config[\"input_channels\"], use_skipAtt=False)"
      ],
      "metadata": {
        "id": "W4TAikGXHdiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ModelCompiler(model,\n",
        "                      working_dir = config[\"working_dir\"],\n",
        "                      out_dir = config[\"out_dir\"],\n",
        "                      num_classes = config[\"n_classes\"],\n",
        "                      inch = config[\"input_channels\"],\n",
        "                      gpu_devices = config[\"gpuDevices\"],\n",
        "                      model_init_type = config[\"init_type\"], \n",
        "                      params_init = config[\"params_init\"],\n",
        "                      freeze_params = config[\"freeze_params\"])"
      ],
      "metadata": {
        "id": "MvHe3STIHgxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_loader,\n",
        "          val_loader, \n",
        "          epochs = config[\"epochs\"], \n",
        "          optimizer_name = config[\"optimizer\"], \n",
        "          lr_init = config[\"LR\"],\n",
        "          lr_policy = config[\"LR_policy\"], \n",
        "          criterion = config[\"criterion\"], \n",
        "          momentum = config[\"momentum\"],\n",
        "          resume = config[\"resume\"],\n",
        "         resume_epoch = config[\"resume_epoch\"])"
      ],
      "metadata": {
        "id": "gRFkihuLHiMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(save_object=\"params\")"
      ],
      "metadata": {
        "id": "5AnQTiGeHl-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.accuracy_evaluation(val_loader, filename=config[\"val_metric_fname\"])"
      ],
      "metadata": {
        "id": "Evnp4uqkHq_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}